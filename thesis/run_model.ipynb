{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizer\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-features#countvectorizer\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-clustering.html#latent-dirichlet-allocation-lda\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.clustering.LDA\n",
    "\n",
    "https://www.zstat.pl/2018/02/07/scala-spark-get-topics-words-from-lda-model/\n",
    "\n",
    "https://stackoverflow.com/questions/51456838/match-index-from-pyspark-dataframe-in-pandas/51457137#51457137\n",
    "\n",
    "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3741049972324885/3783546674231782/4413065072037724/latest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START SPARKSESSION\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "#from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, StopWordsRemover\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.sql.functions import udf\n",
    "#from pyspark.sql.functions import asc, count, col, collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "                    .appName('Topic Modelling') \\\n",
    "                    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 1: TOPIC MODELLING WITH SPARK\n",
    "\n",
    "# Auxiliar functions\n",
    "def equivalent_type(f):\n",
    "    if f == 'datetime64[ns]': return TimestampType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "def define_structure(string, format_type):\n",
    "    try: typo = equivalent_type(format_type)\n",
    "    except: typo = StringType()\n",
    "    return StructField(string, typo)\n",
    "\n",
    "def pandas_to_spark(pandas_df):\n",
    "    columns = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    for column, typo in zip(columns, types): \n",
    "      struct_list.append(define_structure(column, typo))\n",
    "    p_schema = StructType(struct_list)\n",
    "    return spark.createDataFrame(pandas_df, p_schema)\n",
    "\n",
    "#data_df = pandas_to_spark(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PROCESSED DATA \n",
    "data_df_full = spark.read.option('header', True).csv('/home/giangvdq/data/NIPS Papers/papers_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df_full.limit(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|  id|    lemmatize_joined|\n",
      "+----+--------------------+\n",
      "|   1|self organization...|\n",
      "|  10|mean field theory...|\n",
      "| 100|store covariance ...|\n",
      "|1000|bayesian query co...|\n",
      "|1001|neural network en...|\n",
      "|1002|sing neural insta...|\n",
      "|1003|plasticity mediat...|\n",
      "|1004|iceg morphology c...|\n",
      "|1005|real time control...|\n",
      "|1006|real time control...|\n",
      "|1007|learn play game c...|\n",
      "|1008|multidimensional ...|\n",
      "|1009|experimental comp...|\n",
      "| 101|train multilayer ...|\n",
      "|1010|interference lear...|\n",
      "|1011|active learn stat...|\n",
      "|1012|rapid graph base ...|\n",
      "|1013|ocular dominance ...|\n",
      "|1014|associative decor...|\n",
      "|1015|connectionist tec...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP: TOKENIZE\n",
    "\n",
    "# source: https://gist.github.com/Bergvca/a59b127afe46c1c1c479\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"lemmatize_joined\", outputCol=\"words\")\n",
    "wordsDataFrame = tokenizer.transform(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+\n",
      "|  id|    lemmatize_joined|               words|\n",
      "+----+--------------------+--------------------+\n",
      "|   1|self organization...|[self, organizati...|\n",
      "|  10|mean field theory...|[mean, field, the...|\n",
      "| 100|store covariance ...|[store, covarianc...|\n",
      "|1000|bayesian query co...|[bayesian, query,...|\n",
      "|1001|neural network en...|[neural, network,...|\n",
      "|1002|sing neural insta...|[sing, neural, in...|\n",
      "|1003|plasticity mediat...|[plasticity, medi...|\n",
      "|1004|iceg morphology c...|[iceg, morphology...|\n",
      "|1005|real time control...|[real, time, cont...|\n",
      "|1006|real time control...|[real, time, cont...|\n",
      "|1007|learn play game c...|[learn, play, gam...|\n",
      "|1008|multidimensional ...|[multidimensional...|\n",
      "|1009|experimental comp...|[experimental, co...|\n",
      "| 101|train multilayer ...|[train, multilaye...|\n",
      "|1010|interference lear...|[interference, le...|\n",
      "|1011|active learn stat...|[active, learn, s...|\n",
      "|1012|rapid graph base ...|[rapid, graph, ba...|\n",
      "|1013|ocular dominance ...|[ocular, dominanc...|\n",
      "|1014|associative decor...|[associative, dec...|\n",
      "|1015|connectionist tec...|[connectionist, t...|\n",
      "+----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsDataFrame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP: REMOVE X MOST OCCURING WORDS\n",
    "cv_tmp = CountVectorizer(inputCol=\"words\", outputCol=\"tmp_vectors\")\n",
    "cv_tmp_model = cv_tmp.fit(wordsDataFrame)\n",
    "\n",
    "topWords = list(cv_tmp_model.vocabulary[0:200])\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords = topWords)\n",
    "wordsDataFrame = remover.transform(wordsDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use',\n",
       " 'learn',\n",
       " 'data',\n",
       " 'algorithm',\n",
       " 'network',\n",
       " 'time',\n",
       " 'train',\n",
       " 'problem',\n",
       " 'figure',\n",
       " 'give',\n",
       " 'method',\n",
       " 'value',\n",
       " 'distribution',\n",
       " 'number',\n",
       " 'model',\n",
       " 'result',\n",
       " 'state',\n",
       " 'input',\n",
       " 'show',\n",
       " 'image',\n",
       " 'feature',\n",
       " 'parameter',\n",
       " 'point',\n",
       " 'system',\n",
       " 'example',\n",
       " 'base',\n",
       " 'sample',\n",
       " 'process',\n",
       " 'error',\n",
       " 'vector',\n",
       " 'probability',\n",
       " 'case',\n",
       " 'neural',\n",
       " 'information',\n",
       " 'weight',\n",
       " 'matrix',\n",
       " 'approach',\n",
       " 'follow',\n",
       " 'space',\n",
       " 'kernel',\n",
       " 'first',\n",
       " 'estimate',\n",
       " 'different',\n",
       " 'linear',\n",
       " 'test',\n",
       " 'variable',\n",
       " 'mean',\n",
       " 'class',\n",
       " 'find',\n",
       " 'neuron',\n",
       " 'define',\n",
       " 'compute',\n",
       " 'order',\n",
       " 'performance',\n",
       " 'cluster',\n",
       " 'output',\n",
       " 'obtain',\n",
       " 'label',\n",
       " 'term',\n",
       " 'consider',\n",
       " 'gaussian',\n",
       " 'step',\n",
       " 'however',\n",
       " 'experiment',\n",
       " 'structure',\n",
       " 'task',\n",
       " 'make',\n",
       " 'correspond',\n",
       " 'unit',\n",
       " 'large',\n",
       " 'function',\n",
       " 'section',\n",
       " 'since',\n",
       " 'pattern',\n",
       " 'present',\n",
       " 'assume',\n",
       " 'component',\n",
       " 'work',\n",
       " 'classification',\n",
       " 'signal',\n",
       " 'noise',\n",
       " 'analysis',\n",
       " 'represent',\n",
       " 'set',\n",
       " 'form',\n",
       " 'solution',\n",
       " 'average',\n",
       " 'random',\n",
       " 'well',\n",
       " 'optimal',\n",
       " 'thus',\n",
       " 'provide',\n",
       " 'paper',\n",
       " 'note',\n",
       " 'object',\n",
       " 'take',\n",
       " 'sequence',\n",
       " 'apply',\n",
       " 'describe',\n",
       " 'size',\n",
       " 'representation',\n",
       " 'second',\n",
       " 'machine',\n",
       " 'measure',\n",
       " 'rate',\n",
       " 'single',\n",
       " 'prior',\n",
       " 'graph',\n",
       " 'approximation',\n",
       " 'local',\n",
       " 'choose',\n",
       " 'cell',\n",
       " 'perform',\n",
       " 'require',\n",
       " 'bind',\n",
       " 'condition',\n",
       " 'classifier',\n",
       " 'equation',\n",
       " 'spike',\n",
       " 'tree',\n",
       " 'response',\n",
       " 'denote',\n",
       " 'scale',\n",
       " 'generate',\n",
       " 'small',\n",
       " 'propose',\n",
       " 'many',\n",
       " 'level',\n",
       " 'possible',\n",
       " 'simple',\n",
       " 'word',\n",
       " 'change',\n",
       " 'control',\n",
       " 'distance',\n",
       " 'prediction',\n",
       " 'action',\n",
       " 'similar',\n",
       " 'likelihood',\n",
       " 'filter',\n",
       " 'hide',\n",
       " 'would',\n",
       " 'stimulus',\n",
       " 'constraint',\n",
       " 'compare',\n",
       " 'high',\n",
       " 'standard',\n",
       " 'update',\n",
       " 'line',\n",
       " 'policy',\n",
       " 'leave',\n",
       " 'dynamic',\n",
       " 'field',\n",
       " 'know',\n",
       " 'layer',\n",
       " 'increase',\n",
       " 'rule',\n",
       " 'dimensional',\n",
       " 'theorem',\n",
       " 'mixture',\n",
       " 'allow',\n",
       " 'support',\n",
       " 'general',\n",
       " 'bound',\n",
       " 'approximate',\n",
       " 'fix',\n",
       " 'factor',\n",
       " 'bayesian',\n",
       " 'three',\n",
       " 'observe',\n",
       " 'application',\n",
       " 'recognition',\n",
       " 'target',\n",
       " 'independent',\n",
       " 'density',\n",
       " 'zero',\n",
       " 'observation',\n",
       " 'computation',\n",
       " 'need',\n",
       " 'property',\n",
       " 'gradient',\n",
       " 'cost',\n",
       " 'current',\n",
       " 'theory',\n",
       " 'maximum',\n",
       " 'loss',\n",
       " 'right',\n",
       " 'include',\n",
       " 'solve',\n",
       " 'estimation',\n",
       " 'visual',\n",
       " 'variance',\n",
       " 'constant',\n",
       " 'university',\n",
       " 'regression',\n",
       " 'region',\n",
       " 'dimension',\n",
       " 'study',\n",
       " 'optimization',\n",
       " 'inference',\n",
       " 'technique']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+\n",
      "|  id|    lemmatize_joined|               words|            filtered|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "|   1|self organization...|[self, organizati...|[self, organizati...|\n",
      "|  10|mean field theory...|[mean, field, the...|[cortex, artifici...|\n",
      "| 100|store covariance ...|[store, covarianc...|[store, covarianc...|\n",
      "|1000|bayesian query co...|[bayesian, query,...|[query, construct...|\n",
      "|1001|neural network en...|[neural, network,...|[ensemble, cross,...|\n",
      "|1002|sing neural insta...|[sing, neural, in...|[sing, instantiat...|\n",
      "|1003|plasticity mediat...|[plasticity, medi...|[plasticity, medi...|\n",
      "|1004|iceg morphology c...|[iceg, morphology...|[iceg, morphology...|\n",
      "|1005|real time control...|[real, time, cont...|[real, tokamak, p...|\n",
      "|1006|real time control...|[real, time, cont...|[real, tokamak, p...|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsDataFrame.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP: COUNTVECTORIZER\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"vectors\")\n",
    "cvmodel = cv.fit(wordsDataFrame)\n",
    "df_vect = cvmodel.transform(wordsDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the dataframe to a format that can be used as input for LDA.train. \n",
    "#LDA train expects a RDD with lists,\n",
    "#where the list consists of a uid and (sparse) Vector\n",
    "def parseVectors(line):\n",
    "    return [ int(line[2]), line[0] ]\n",
    "\n",
    "sparsevector = (df_vect.select('vectors', 'lemmatize_joined', 'id')\n",
    "                .rdd.map(parseVectors) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsevector = sparsevector.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the LDA model\n",
    "\n",
    "lda = LDA(k=4, maxIter=70, featuresCol='_2', seed=1, optimizer='em')\n",
    "model = lda.fit(sparsevector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75334"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cortex',\n",
       " 'exact',\n",
       " 'vision',\n",
       " 'illustrate',\n",
       " 'direct',\n",
       " 'significant',\n",
       " 'trajectory',\n",
       " 'capture',\n",
       " 'advantage',\n",
       " 'category',\n",
       " 'query',\n",
       " 'specify',\n",
       " 'separate',\n",
       " 'randomly',\n",
       " 'various',\n",
       " 'prove',\n",
       " 'cambridge',\n",
       " 'transform',\n",
       " 'reinforcement',\n",
       " 'amount',\n",
       " 'manifold',\n",
       " 'dependent',\n",
       " 'always',\n",
       " 'online',\n",
       " 'boost',\n",
       " 'adaptive',\n",
       " 'coordinate',\n",
       " 'mechanism',\n",
       " 'still',\n",
       " 'fast',\n",
       " 'world',\n",
       " 'expression',\n",
       " 'ratio',\n",
       " 'generative',\n",
       " 'implementation',\n",
       " 'population',\n",
       " 'main',\n",
       " 'expectation',\n",
       " 'address',\n",
       " 'free',\n",
       " 'can',\n",
       " 'user',\n",
       " 'chain',\n",
       " 'department',\n",
       " 'variational',\n",
       " 'not',\n",
       " 'see',\n",
       " 'identify',\n",
       " 'activation',\n",
       " 'language',\n",
       " 'consistent',\n",
       " 'frame',\n",
       " 'turn',\n",
       " 'assign',\n",
       " 'relationship',\n",
       " 'environment',\n",
       " 'validation',\n",
       " 'simply',\n",
       " 'conclusion',\n",
       " 'run',\n",
       " 'underlie',\n",
       " 'complete',\n",
       " 'addition',\n",
       " 'whether',\n",
       " 'imply',\n",
       " 'uniform',\n",
       " 'bay',\n",
       " 'interval',\n",
       " 'movement',\n",
       " 'chip',\n",
       " 'significantly',\n",
       " 'theoretical',\n",
       " 'difficult',\n",
       " 'formulation',\n",
       " 'among',\n",
       " 'code',\n",
       " 'record',\n",
       " 'artificial',\n",
       " 'refer',\n",
       " 'link',\n",
       " 'typically',\n",
       " 'delay',\n",
       " 'measurement',\n",
       " 'dimensionality',\n",
       " 'relation',\n",
       " 'reduction',\n",
       " 'place',\n",
       " 'arbitrary',\n",
       " 'pas',\n",
       " 'cause',\n",
       " 'future',\n",
       " 'sense',\n",
       " 'nature',\n",
       " 'hierarchical',\n",
       " 'guarantee',\n",
       " 'patch',\n",
       " 'extract',\n",
       " 'otherwise',\n",
       " 'international',\n",
       " 'appropriate',\n",
       " 'smaller',\n",
       " 'exponential',\n",
       " 'improvement',\n",
       " 'easily',\n",
       " 'side',\n",
       " 'derivative',\n",
       " 'relevant',\n",
       " 'robot',\n",
       " 'speed',\n",
       " 'unknown',\n",
       " 'evaluation',\n",
       " 'detect',\n",
       " 'text',\n",
       " 'family',\n",
       " 'noisy',\n",
       " 'database',\n",
       " 'embed',\n",
       " 'last',\n",
       " 'spectral',\n",
       " 'evidence',\n",
       " 'graphical',\n",
       " 'principle',\n",
       " 'robust',\n",
       " 'technical',\n",
       " 'certain',\n",
       " 'segmentation',\n",
       " 'receive',\n",
       " 'unlabeled',\n",
       " 'scene',\n",
       " 'basic',\n",
       " 'semi',\n",
       " 'return',\n",
       " 'back',\n",
       " 'uncertainty',\n",
       " 'motor',\n",
       " 'final',\n",
       " 'question',\n",
       " 'datasets',\n",
       " 'parallel',\n",
       " 'recent',\n",
       " 'cortical',\n",
       " 'effective',\n",
       " 'simulate',\n",
       " 'reason',\n",
       " 'operation',\n",
       " 'likely',\n",
       " 'shift',\n",
       " 'integrate',\n",
       " 'constrain',\n",
       " 'marginal',\n",
       " 'mix',\n",
       " 'alternative',\n",
       " 'explain',\n",
       " 'sensor',\n",
       " 'bottom',\n",
       " 'practice',\n",
       " 'track',\n",
       " 'around',\n",
       " 'mode',\n",
       " 'exactly',\n",
       " 'deviation',\n",
       " 'reach',\n",
       " 'analyze',\n",
       " 'furthermore',\n",
       " 'quadratic',\n",
       " 'operator',\n",
       " 'do',\n",
       " 'functional',\n",
       " 'message',\n",
       " 'special',\n",
       " 'understand',\n",
       " 'replace',\n",
       " 'nearest',\n",
       " 'volume',\n",
       " 'analog',\n",
       " 'subspace',\n",
       " 'color',\n",
       " 'window',\n",
       " 'inverse',\n",
       " 'polynomial',\n",
       " 'editor',\n",
       " 'stage',\n",
       " 'express',\n",
       " 'fit',\n",
       " 'classify',\n",
       " 'principal',\n",
       " 'concept',\n",
       " 'forward',\n",
       " 'necessary',\n",
       " 'count',\n",
       " 'background',\n",
       " 'feedback',\n",
       " 'symmetric',\n",
       " 'grid',\n",
       " 'dual',\n",
       " 'project',\n",
       " 'normal',\n",
       " 'stable',\n",
       " 'employ',\n",
       " 'nip',\n",
       " 'reconstruction',\n",
       " 'recurrent',\n",
       " 'self',\n",
       " 'usually',\n",
       " 'play',\n",
       " 'dependency',\n",
       " 'together',\n",
       " 'incorporate',\n",
       " 'restrict',\n",
       " 'equilibrium',\n",
       " 'plan',\n",
       " 'explore',\n",
       " 'weak',\n",
       " 'resolution',\n",
       " 'induce',\n",
       " 'desire',\n",
       " 'vertex',\n",
       " 'novel',\n",
       " 'create',\n",
       " 'diagonal',\n",
       " 'surface',\n",
       " 'inequality',\n",
       " 'repeat',\n",
       " 'infer',\n",
       " 'overlap',\n",
       " 'institute',\n",
       " 'sufficient',\n",
       " 'seem',\n",
       " 'strength',\n",
       " 'adaptation',\n",
       " 'split',\n",
       " 'recently',\n",
       " 'player',\n",
       " 'assignment',\n",
       " 'strong',\n",
       " 'miss',\n",
       " 'receptive',\n",
       " 'highly',\n",
       " 'separation',\n",
       " 'quality',\n",
       " 'extension',\n",
       " 'share',\n",
       " 'gate',\n",
       " 'digit',\n",
       " 'synapsis',\n",
       " 'variation',\n",
       " 'descent',\n",
       " 'configuration',\n",
       " 'third',\n",
       " 'cycle',\n",
       " 'avoid',\n",
       " 'divergence',\n",
       " 'remove',\n",
       " 'decomposition',\n",
       " 'intelligence',\n",
       " 'infinite',\n",
       " 'unsupervised',\n",
       " 'overall',\n",
       " 'moreover',\n",
       " 'voltage',\n",
       " 'suppose',\n",
       " 'stationary',\n",
       " 'though',\n",
       " 'clearly',\n",
       " 'recall',\n",
       " 'issue',\n",
       " 'recover',\n",
       " 'role',\n",
       " 'characteristic',\n",
       " 'approximately',\n",
       " 'learner',\n",
       " 'couple',\n",
       " 'minimization',\n",
       " 'situation',\n",
       " 'store',\n",
       " 'accurate',\n",
       " 'modify',\n",
       " 'correlate',\n",
       " 'predictive',\n",
       " 'trace',\n",
       " 'ability',\n",
       " 'actual',\n",
       " 'quite',\n",
       " 'investigate',\n",
       " 'ensemble',\n",
       " 'practical',\n",
       " 'attention',\n",
       " 'look',\n",
       " 'period',\n",
       " 'quantity',\n",
       " 'entry',\n",
       " 'short',\n",
       " 'author',\n",
       " 'biological',\n",
       " 'invariant',\n",
       " 'characterize',\n",
       " 'similarly',\n",
       " 'easy',\n",
       " 'switch',\n",
       " 'exploit',\n",
       " 'hard',\n",
       " 'near',\n",
       " 'mutual',\n",
       " 'magnitude',\n",
       " 'influence',\n",
       " 'enough',\n",
       " 'jordan',\n",
       " 'generally',\n",
       " 'pose',\n",
       " 'controller',\n",
       " 'contribution',\n",
       " 'sign',\n",
       " 'gibbs',\n",
       " 'efficiently',\n",
       " 'contour',\n",
       " 'protein',\n",
       " 'keep',\n",
       " 'tend',\n",
       " 'detector',\n",
       " 'greedy',\n",
       " 'previously',\n",
       " 'attempt',\n",
       " 'transfer',\n",
       " 'york',\n",
       " 'clear',\n",
       " 'gene',\n",
       " 'begin',\n",
       " 'ensure',\n",
       " 'http',\n",
       " 'notation',\n",
       " 'head',\n",
       " 'dependence',\n",
       " 'description',\n",
       " 'pairwise',\n",
       " 'sensory',\n",
       " 'review',\n",
       " 'identical',\n",
       " 'drive',\n",
       " 'attribute',\n",
       " 'one',\n",
       " 'whereas',\n",
       " 'carlo',\n",
       " 'monte',\n",
       " 'spectrum',\n",
       " 'indeed',\n",
       " 'typical',\n",
       " 'adapt',\n",
       " 'internal',\n",
       " 'particle',\n",
       " 'angle',\n",
       " 'velocity',\n",
       " 'almost',\n",
       " 'expansion',\n",
       " 'light',\n",
       " 'auditory',\n",
       " 'fully',\n",
       " 'letter',\n",
       " 'perceptron',\n",
       " 'heuristic',\n",
       " 'speaker',\n",
       " 'interpretation',\n",
       " 'relatively',\n",
       " 'simplify',\n",
       " 'entire',\n",
       " 'precision',\n",
       " 'specifically',\n",
       " 'collection',\n",
       " 'axis',\n",
       " 'panel',\n",
       " 'cover',\n",
       " 'faster',\n",
       " 'reflect',\n",
       " 'eigenvectors',\n",
       " 'examine',\n",
       " 'except',\n",
       " 'discriminative',\n",
       " 'engineer',\n",
       " 'technology',\n",
       " 'outperform',\n",
       " 'root',\n",
       " 'template',\n",
       " 'excitatory',\n",
       " 'grow',\n",
       " 'thank',\n",
       " 'purpose',\n",
       " 'parametric',\n",
       " 'peak',\n",
       " 'flow',\n",
       " 'come',\n",
       " 'deterministic',\n",
       " 'baseline',\n",
       " 'explicitly',\n",
       " 'partial',\n",
       " 'establish',\n",
       " 'aspect',\n",
       " 'affect',\n",
       " 'importance',\n",
       " 'arise',\n",
       " 'sequential',\n",
       " 'course',\n",
       " 'independently',\n",
       " 'whole',\n",
       " 'iterative',\n",
       " 'width',\n",
       " 'decay',\n",
       " 'rotation',\n",
       " 'sound',\n",
       " 'presence',\n",
       " 'loop',\n",
       " 'deal',\n",
       " 'logistic',\n",
       " 'exhibit',\n",
       " 'regularize',\n",
       " 'dynamical',\n",
       " 'numerical',\n",
       " 'confidence',\n",
       " 'alignment',\n",
       " 'transaction',\n",
       " 'synapse',\n",
       " 'video',\n",
       " 'depth',\n",
       " 'walk',\n",
       " 'histogram',\n",
       " 'differ',\n",
       " 'grant',\n",
       " 'five',\n",
       " 'largest',\n",
       " 'interpret',\n",
       " 'stability',\n",
       " 'onto',\n",
       " 'inhibitory',\n",
       " 'candidate',\n",
       " 'belong',\n",
       " 'list',\n",
       " 'unique',\n",
       " 'handle',\n",
       " 'trans',\n",
       " 'maintain',\n",
       " 'neighborhood',\n",
       " 'springer',\n",
       " 'stop',\n",
       " 'literature',\n",
       " 'simultaneously',\n",
       " 'solid',\n",
       " 'normalization',\n",
       " 'slightly',\n",
       " 'dirichlet',\n",
       " 'development',\n",
       " 'actually',\n",
       " 'span',\n",
       " 'greater',\n",
       " 'early',\n",
       " 'sentence',\n",
       " 'identity',\n",
       " 'locally',\n",
       " 'treat',\n",
       " 'dash',\n",
       " 'carry',\n",
       " 'classical',\n",
       " 'already',\n",
       " 'fisher',\n",
       " 'translation',\n",
       " 'display',\n",
       " 'decode',\n",
       " 'latter',\n",
       " 'differential',\n",
       " 'string',\n",
       " 'initialize',\n",
       " 'wide',\n",
       " 'linearly',\n",
       " 'svms',\n",
       " 'array',\n",
       " 'retrieval',\n",
       " 'variety',\n",
       " 'gaussians',\n",
       " 'hinton',\n",
       " 'asymptotic',\n",
       " 'child',\n",
       " 'relaxation',\n",
       " 'capacity',\n",
       " 'force',\n",
       " 'challenge',\n",
       " 'computationally',\n",
       " 'variant',\n",
       " 'character',\n",
       " 'module',\n",
       " 'correctly',\n",
       " 'uniformly',\n",
       " 'amplitude',\n",
       " 'false',\n",
       " 'others',\n",
       " 'preference',\n",
       " 'explicit',\n",
       " 'corpus',\n",
       " 'communication',\n",
       " 'neuronal',\n",
       " 'construction',\n",
       " 'fraction',\n",
       " 'open',\n",
       " 'minimal',\n",
       " 'bit',\n",
       " 'half',\n",
       " 'critical',\n",
       " 'upon',\n",
       " 'penalty',\n",
       " 'want',\n",
       " 'rely',\n",
       " 'towards',\n",
       " 'independence',\n",
       " 'sensitive',\n",
       " 'notice',\n",
       " 'parent',\n",
       " 'additive',\n",
       " 'argument',\n",
       " 'cognitive',\n",
       " 'straightforward',\n",
       " 'sparsity',\n",
       " 'adaboost',\n",
       " 'simplicity',\n",
       " 'intensity',\n",
       " 'operate',\n",
       " 'formulate',\n",
       " 'euclidean',\n",
       " 'synthetic',\n",
       " 'connectivity',\n",
       " 'divide',\n",
       " 'inner',\n",
       " 'kind',\n",
       " 'consistency',\n",
       " 'partially',\n",
       " 'manner',\n",
       " 'summarize',\n",
       " 'motivate',\n",
       " 'reasonable',\n",
       " 'prune',\n",
       " 'little',\n",
       " 'help',\n",
       " 'longer',\n",
       " 'morgan',\n",
       " 'membrane',\n",
       " 'regret',\n",
       " 'calculation',\n",
       " 'integration',\n",
       " 'white',\n",
       " 'rest',\n",
       " 'central',\n",
       " 'neuroscience',\n",
       " 'way',\n",
       " 'soft',\n",
       " 'plane',\n",
       " 'history',\n",
       " 'proportional',\n",
       " 'mathematical',\n",
       " 'black',\n",
       " 'later',\n",
       " 'enable',\n",
       " 'round',\n",
       " 'think',\n",
       " 'particularly',\n",
       " 'fail',\n",
       " 'item',\n",
       " 'laplacian',\n",
       " 'maximization',\n",
       " 'relevance',\n",
       " 'versus',\n",
       " 'balance',\n",
       " 'sufficiently',\n",
       " 'texture',\n",
       " 'vertical',\n",
       " 'difficulty',\n",
       " 'ignore',\n",
       " 'recognize',\n",
       " 'try',\n",
       " 'parse',\n",
       " 'acknowledgment',\n",
       " 'perception',\n",
       " 'body',\n",
       " 'causal',\n",
       " 'maximal',\n",
       " 'proposition',\n",
       " 'appearance',\n",
       " 'distinct',\n",
       " 'integral',\n",
       " 'discrimination',\n",
       " 'symbol',\n",
       " 'processor',\n",
       " 'regard',\n",
       " 'exploration',\n",
       " 'acoustic',\n",
       " 'dot',\n",
       " 'temperature',\n",
       " 'automatically',\n",
       " 'mass',\n",
       " 'preserve',\n",
       " 'band',\n",
       " 'hierarchy',\n",
       " 'primary',\n",
       " 'notion',\n",
       " 'organize',\n",
       " 'slow',\n",
       " 'collect',\n",
       " 'tool',\n",
       " 'row',\n",
       " 'association',\n",
       " 'cue',\n",
       " 'grammar',\n",
       " 'sum',\n",
       " 'efficiency',\n",
       " 'wavelet',\n",
       " 'definite',\n",
       " 'pick',\n",
       " 'adjust',\n",
       " 'orthogonal',\n",
       " 'essentially',\n",
       " 'prefer',\n",
       " 'especially',\n",
       " 'attractor',\n",
       " 'localization',\n",
       " 'semantic',\n",
       " 'break',\n",
       " 'competitive',\n",
       " 'foundation',\n",
       " 'completely',\n",
       " 'mention',\n",
       " 'scan',\n",
       " 'roughly',\n",
       " 'strongly',\n",
       " 'correspondence',\n",
       " 'generation',\n",
       " 'requirement',\n",
       " 'name',\n",
       " 'automatic',\n",
       " 'john',\n",
       " 'lateral',\n",
       " 'horizontal',\n",
       " 'stream',\n",
       " 'inhibition',\n",
       " 'people',\n",
       " 'naive',\n",
       " 'limitation',\n",
       " 'predictor',\n",
       " 'multivariate',\n",
       " 'circle',\n",
       " 'geometric',\n",
       " 'valid',\n",
       " 'vlsi',\n",
       " 'sort',\n",
       " 'namely',\n",
       " 'animal',\n",
       " 'fold',\n",
       " 'hyperparameters',\n",
       " 'expand',\n",
       " 'disparity',\n",
       " 'optimum',\n",
       " 'closely',\n",
       " 'suitable',\n",
       " 'impose',\n",
       " 'extraction',\n",
       " 'concern',\n",
       " 'benefit',\n",
       " 'society',\n",
       " 'reveal',\n",
       " 'option',\n",
       " 'modification',\n",
       " 'selective',\n",
       " 'experience',\n",
       " 'sensitivity',\n",
       " 'compact',\n",
       " 'phenomenon',\n",
       " 'discover',\n",
       " 'saliency',\n",
       " 'branch',\n",
       " 'unlike',\n",
       " 'setting',\n",
       " 'conclude',\n",
       " 'consequence',\n",
       " 'mark',\n",
       " 'poisson',\n",
       " 'structural',\n",
       " 'trade',\n",
       " 'batch',\n",
       " 'distinguish',\n",
       " 'currently',\n",
       " 'integer',\n",
       " 'discount',\n",
       " 'content',\n",
       " 'california',\n",
       " 'naturally',\n",
       " 'outcome',\n",
       " 'profile',\n",
       " 'highest',\n",
       " 'past',\n",
       " 'post',\n",
       " 'invariance',\n",
       " 'earlier',\n",
       " 'absolute',\n",
       " 'derivation',\n",
       " 'conventional',\n",
       " 'grind',\n",
       " 'discriminant',\n",
       " 'pool',\n",
       " 'go',\n",
       " 'feedforward',\n",
       " 'pulse',\n",
       " 'perceptual',\n",
       " 'ball',\n",
       " 'variability',\n",
       " 'effectively',\n",
       " 'priori',\n",
       " 'perturbation',\n",
       " 'success',\n",
       " 'serve',\n",
       " 'align',\n",
       " 'external',\n",
       " 'student',\n",
       " 'net',\n",
       " 'believe',\n",
       " 'traditional',\n",
       " 'nonparametric',\n",
       " 'bar',\n",
       " 'middle',\n",
       " 'kalman',\n",
       " 'successful',\n",
       " 'berkeley',\n",
       " 'beyond',\n",
       " 'identification',\n",
       " 'taylor',\n",
       " 'williams',\n",
       " 'evolution',\n",
       " 'possibly',\n",
       " 'regular',\n",
       " 'comparable',\n",
       " 'kaufmann',\n",
       " 'respond',\n",
       " 'compression',\n",
       " 'answer',\n",
       " 'vapnik',\n",
       " 'presentation',\n",
       " 'scalar',\n",
       " 'omit',\n",
       " 'residual',\n",
       " 'epoch',\n",
       " 'anneal',\n",
       " 'reconstruct',\n",
       " 'unfortunately',\n",
       " 'prototype',\n",
       " 'acknowledgement',\n",
       " 'competition',\n",
       " 'dept',\n",
       " 'ideal',\n",
       " 'benchmark',\n",
       " 'scenario',\n",
       " 'organization',\n",
       " 'successfully',\n",
       " 'formula',\n",
       " 'offer',\n",
       " 'compose',\n",
       " 'proposal',\n",
       " 'connectionist',\n",
       " 'possibility',\n",
       " 'smallest',\n",
       " 'tractable',\n",
       " 'intrinsic',\n",
       " 'plasticity',\n",
       " 'conf',\n",
       " 'hebbian',\n",
       " 'device',\n",
       " 'sutton',\n",
       " 'national',\n",
       " 'permutation',\n",
       " 'smola',\n",
       " 'major',\n",
       " 'sejnowski',\n",
       " 'digital',\n",
       " 'blind',\n",
       " 'exponentially',\n",
       " 'smoothness',\n",
       " 'feasible',\n",
       " 'consequently',\n",
       " 'away',\n",
       " 'worse',\n",
       " 'laboratory',\n",
       " 'fourier',\n",
       " 'quickly',\n",
       " 'conjugate',\n",
       " 'associative',\n",
       " 'depict',\n",
       " 'mcmc',\n",
       " 'simpler',\n",
       " 'load',\n",
       " 'postsynaptic',\n",
       " 'rise',\n",
       " 'indicator',\n",
       " 'recursive',\n",
       " 'proportion',\n",
       " 'formally',\n",
       " 'penalize',\n",
       " 'year',\n",
       " 'clique',\n",
       " 'fall',\n",
       " 'camera',\n",
       " 'observable',\n",
       " 'visible',\n",
       " 'paradigm',\n",
       " 'occurrence',\n",
       " 'eliminate',\n",
       " 'schedule',\n",
       " 'decompose',\n",
       " 'member',\n",
       " 'utility',\n",
       " 'wish',\n",
       " 'icml',\n",
       " 'wiley',\n",
       " 'physical',\n",
       " 'adopt',\n",
       " 'outlier',\n",
       " 'hyperplane',\n",
       " 'storage',\n",
       " 'widely',\n",
       " 'activate',\n",
       " 'necessarily',\n",
       " 'physic',\n",
       " 'pathway',\n",
       " 'worst',\n",
       " 'utilize',\n",
       " 'factorization',\n",
       " 'diagram',\n",
       " 'moment',\n",
       " 'david',\n",
       " 'marginals',\n",
       " 'read',\n",
       " 'topology',\n",
       " 'gray',\n",
       " 'expensive',\n",
       " 'trivial',\n",
       " 'multinomial',\n",
       " 'neurosci',\n",
       " 'popular',\n",
       " 'regime',\n",
       " 'seek',\n",
       " 'stag',\n",
       " 'never',\n",
       " 'despite',\n",
       " 'diffusion',\n",
       " 'summary',\n",
       " 'stanford',\n",
       " 'lie',\n",
       " 'fundamental',\n",
       " 'realistic',\n",
       " 'teacher',\n",
       " 'outline',\n",
       " 'outside',\n",
       " 'mistake',\n",
       " 'lasso',\n",
       " 'interpolation',\n",
       " 'hmms',\n",
       " 'workshop',\n",
       " 'accurately',\n",
       " 'corollary',\n",
       " 'modulation',\n",
       " 'observer',\n",
       " 'perspective',\n",
       " 'usual',\n",
       " 'empirically',\n",
       " 'duration',\n",
       " 'applicable',\n",
       " 'hybrid',\n",
       " 'equally',\n",
       " 'distortion',\n",
       " 'poor',\n",
       " 'enforce',\n",
       " 'extra',\n",
       " 'theoretic',\n",
       " 'lack',\n",
       " 'precisely',\n",
       " 'alone',\n",
       " 'multiply',\n",
       " 'retina',\n",
       " 'geometry',\n",
       " 'pseudo',\n",
       " 'perfect',\n",
       " 'check',\n",
       " 'audio',\n",
       " 'equivalence',\n",
       " 'ghahramani',\n",
       " 'incremental',\n",
       " 'winner',\n",
       " 'subsequent',\n",
       " 'contribute',\n",
       " 'reproduce',\n",
       " 'drop',\n",
       " 'thesis',\n",
       " 'radius',\n",
       " 'dominate',\n",
       " 'separable',\n",
       " 'throughout',\n",
       " 'strictly',\n",
       " 'initially',\n",
       " 'verify',\n",
       " 'access',\n",
       " 'transistor',\n",
       " 'tangent',\n",
       " 'verlag',\n",
       " 'merge',\n",
       " 'potentially',\n",
       " 'diag',\n",
       " 'insight',\n",
       " 'preliminary',\n",
       " 'extremely',\n",
       " 'mask',\n",
       " 'intractable',\n",
       " 'terminal',\n",
       " 'accept',\n",
       " 'intermediate',\n",
       " 'decide',\n",
       " 'iterate',\n",
       " 'radial',\n",
       " 'continue',\n",
       " 'percentage',\n",
       " 'initialization',\n",
       " 'vote',\n",
       " 'bandwidth',\n",
       " 'hardware',\n",
       " 'categorization',\n",
       " 'boltzmann',\n",
       " 'michael',\n",
       " 'ass',\n",
       " 'whenever',\n",
       " 'claim',\n",
       " 'shall',\n",
       " 'concentration',\n",
       " 'happen',\n",
       " 'double',\n",
       " 'backward',\n",
       " 'plus',\n",
       " 'school',\n",
       " 'correction',\n",
       " 'execute',\n",
       " 'commonly',\n",
       " 'generic',\n",
       " 'origin',\n",
       " 'powerful',\n",
       " 'gamma',\n",
       " 'eigenvector',\n",
       " 'resource',\n",
       " 'sometimes',\n",
       " 'inside',\n",
       " 'overfitting',\n",
       " 'parameterized',\n",
       " 'localize',\n",
       " 'precise',\n",
       " 'optimality',\n",
       " 'lattice',\n",
       " 'nearly',\n",
       " 'surround',\n",
       " 'arrive',\n",
       " 'wise',\n",
       " 'sigmoid',\n",
       " 'prevent',\n",
       " 'analogous',\n",
       " 'superior',\n",
       " 'analytically',\n",
       " 'absence',\n",
       " 'hopfield',\n",
       " 'relax',\n",
       " 'robustness',\n",
       " 'complicate',\n",
       " 'price',\n",
       " 'explanation',\n",
       " 'london',\n",
       " 'rewrite',\n",
       " 'conductance',\n",
       " 'style',\n",
       " 'offset',\n",
       " 'asymptotically',\n",
       " 'fewer',\n",
       " 'obvious',\n",
       " 'guide',\n",
       " 'essential',\n",
       " 'existence',\n",
       " 'software',\n",
       " 'statistically',\n",
       " 'singular',\n",
       " 'zhang',\n",
       " 'somewhat',\n",
       " 'quantify',\n",
       " 'intuitively',\n",
       " 'symmetry',\n",
       " 'propagate',\n",
       " 'phrase',\n",
       " 'dictionary',\n",
       " 'behavioral',\n",
       " 'harmonic',\n",
       " 'separately',\n",
       " 'leaf',\n",
       " 'backpropagation',\n",
       " 'surprise',\n",
       " 'person',\n",
       " 'relational',\n",
       " 'static',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmodel.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -38942653.72330608\n",
      "The upper bound on perplexity: 18.500134548336305\n"
     ]
    }
   ],
   "source": [
    "ll = model.logLikelihood(sparsevector)\n",
    "lp = model.logPerplexity(sparsevector)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[0, 68, 69, 81, 3...|[0.00445160280738...|\n",
      "|    1|[10, 18, 41, 107,...|[0.00446965231844...|\n",
      "|    2|[49, 9, 93, 33, 8...|[0.00466845859372...|\n",
      "|    3|[20, 73, 83, 127,...|[0.00364356705031...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "\n",
    "# Number of terms in topics\n",
    "numTerms = 8\n",
    "\n",
    "topics = model.describeTopics(numTerms)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------+\n",
      "|topic|topics_words                                                                       |\n",
      "+-----+-----------------------------------------------------------------------------------+\n",
      "|0    |[cortex, movement, chip, delay, population, motor, mechanism, cortical]            |\n",
      "|1    |[query, reinforcement, user, robot, plan, patch, track, player]                    |\n",
      "|2    |[language, category, hierarchical, generative, relation, perceptron, speaker, text]|\n",
      "|3    |[manifold, formulation, dimensionality, unlabeled, embed, prove, subspace, semi]   |\n",
      "+-----+-----------------------------------------------------------------------------------+\n",
      "\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|        topics_words|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    0|[0, 68, 69, 81, 3...|[0.00445160280738...|[cortex, movement...|\n",
      "|    1|[10, 18, 41, 107,...|[0.00446965231844...|[query, reinforce...|\n",
      "|    2|[49, 9, 93, 33, 8...|[0.00466845859372...|[language, catego...|\n",
      "|    3|[20, 73, 83, 127,...|[0.00364356705031...|[manifold, formul...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY THE TOPIC DISTRIBUTION\n",
    "\n",
    "def indices_to_terms(vocabulary):\n",
    "    def indices_to_terms(xs):\n",
    "        return [vocabulary[int(x)] for x in xs]\n",
    "    return udf(indices_to_terms, ArrayType(StringType()))\n",
    "\n",
    "topics_with_terms = topics.withColumn(\n",
    "    \"topics_words\", indices_to_terms(cvmodel.vocabulary)(\"termIndices\"))\n",
    "\n",
    "#topics_with_terms.select(['topic','topics_words']).show(20,False)\n",
    "topics_with_terms.select(['topic','topics_words']).show(20,False)\n",
    "\n",
    "topics_with_terms.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: vector (nullable = true)\n",
      " |-- topicDistribution: vector (nullable = true)\n",
      "\n",
      "+----+-----------------------------------------------------------------------------------+\n",
      "|_1  |topicDistribution                                                                  |\n",
      "+----+-----------------------------------------------------------------------------------+\n",
      "|1   |[0.14339740836927742,0.49296136110318556,0.23241814962348656,0.1312230809040504]   |\n",
      "|10  |[0.8101573742702054,0.05280950885829635,0.07346853379876724,0.0635645830727309]    |\n",
      "|100 |[0.9292264251707395,0.024301153439354503,0.027989042771909344,0.018483378617996475]|\n",
      "|1000|[0.06386774955866174,0.505254604713889,0.256530875064119,0.17434677066333015]      |\n",
      "|1001|[0.07547023431497453,0.11683414019216311,0.5198599207355684,0.2878357047572939]    |\n",
      "|1002|[0.05789021243946618,0.24199817987376968,0.5102892432532927,0.18982236443347145]   |\n",
      "|1003|[0.5176273149800396,0.0714811472793829,0.24515391959957805,0.16573761814099947]    |\n",
      "|1004|[0.7504914829754115,0.12582366304937576,0.06040823993275285,0.06327661404245984]   |\n",
      "|1005|[0.7427655163408927,0.07781604657950558,0.09170169693109492,0.08771674014850675]   |\n",
      "|1006|[0.8638089464219316,0.04105594780507009,0.049723904573292656,0.04541120119970566]  |\n",
      "+----+-----------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shows the result\n",
    "docTopic = model.transform(sparsevector)\n",
    "docTopic.printSchema()\n",
    "docTopic.select(['_1','topicDistribution']).show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hello it's me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
