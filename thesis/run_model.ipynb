{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizer\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-features#countvectorizer\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-clustering.html#latent-dirichlet-allocation-lda\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.clustering.LDA\n",
    "\n",
    "https://www.zstat.pl/2018/02/07/scala-spark-get-topics-words-from-lda-model/\n",
    "\n",
    "https://stackoverflow.com/questions/51456838/match-index-from-pyspark-dataframe-in-pandas/51457137#51457137\n",
    "\n",
    "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3741049972324885/3783546674231782/4413065072037724/latest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START SPARKSESSION\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "#from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, StopWordsRemover\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.sql.functions import udf\n",
    "#from pyspark.sql.functions import asc, count, col, collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "                    .appName('Topic Modelling') \\\n",
    "                    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 1: TOPIC MODELLING WITH SPARK\n",
    "\n",
    "# Auxiliar functions\n",
    "def equivalent_type(f):\n",
    "    if f == 'datetime64[ns]': return TimestampType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "def define_structure(string, format_type):\n",
    "    try: typo = equivalent_type(format_type)\n",
    "    except: typo = StringType()\n",
    "    return StructField(string, typo)\n",
    "\n",
    "def pandas_to_spark(pandas_df):\n",
    "    columns = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    for column, typo in zip(columns, types): \n",
    "      struct_list.append(define_structure(column, typo))\n",
    "    p_schema = StructType(struct_list)\n",
    "    return spark.createDataFrame(pandas_df, p_schema)\n",
    "\n",
    "#data_df = pandas_to_spark(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PROCESSED DATA \n",
    "data_df_full = spark.read.option('header', True).csv('/home/giangvdq/data/NIPS Papers/papers_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df_full.limit(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP: TOKENIZE\n",
    "\n",
    "# source: https://gist.github.com/Bergvca/a59b127afe46c1c1c479\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"lemmatize_joined\", outputCol=\"words\")\n",
    "wordsDataFrame = tokenizer.transform(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP: REMOVE X MOST OCCURING WORDS\n",
    "cv_tmp = CountVectorizer(inputCol=\"words\", outputCol=\"tmp_vectors\")\n",
    "cv_tmp_model = cv_tmp.fit(wordsDataFrame)\n",
    "\n",
    "topWords = list(cv_tmp_model.vocabulary[0:500])\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords = topWords)\n",
    "wordsDataFrame = remover.transform(wordsDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP: COUNTVECTORIZER\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"vectors\")\n",
    "cvmodel = cv.fit(wordsDataFrame)\n",
    "df_vect = cvmodel.transform(wordsDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the dataframe to a format that can be used as input for LDA.train. \n",
    "#LDA train expects a RDD with lists,\n",
    "#where the list consists of a uid and (sparse) Vector\n",
    "def parseVectors(line):\n",
    "    return [ int(line[2]), line[0] ]\n",
    "\n",
    "sparsevector = (df_vect.select('vectors', 'lemmatize_joined', 'id')\n",
    "                .rdd.map(parseVectors) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsevector = sparsevector.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the LDA model\n",
    "\n",
    "lda = LDA(k=10, maxIter=50, featuresCol='_2', seed=1, optimizer='em')\n",
    "model = lda.fit(sparsevector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75334"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cortex',\n",
       " 'exact',\n",
       " 'vision',\n",
       " 'illustrate',\n",
       " 'direct',\n",
       " 'significant',\n",
       " 'trajectory',\n",
       " 'capture',\n",
       " 'advantage',\n",
       " 'category',\n",
       " 'query',\n",
       " 'specify',\n",
       " 'separate',\n",
       " 'randomly',\n",
       " 'various',\n",
       " 'prove',\n",
       " 'cambridge',\n",
       " 'transform',\n",
       " 'reinforcement',\n",
       " 'amount',\n",
       " 'manifold',\n",
       " 'dependent',\n",
       " 'always',\n",
       " 'online',\n",
       " 'boost',\n",
       " 'adaptive',\n",
       " 'coordinate',\n",
       " 'mechanism',\n",
       " 'still',\n",
       " 'fast',\n",
       " 'world',\n",
       " 'expression',\n",
       " 'ratio',\n",
       " 'generative',\n",
       " 'implementation',\n",
       " 'population',\n",
       " 'main',\n",
       " 'expectation',\n",
       " 'address',\n",
       " 'free',\n",
       " 'can',\n",
       " 'user',\n",
       " 'chain',\n",
       " 'department',\n",
       " 'variational',\n",
       " 'not',\n",
       " 'see',\n",
       " 'identify',\n",
       " 'activation',\n",
       " 'language',\n",
       " 'consistent',\n",
       " 'frame',\n",
       " 'turn',\n",
       " 'assign',\n",
       " 'relationship',\n",
       " 'environment',\n",
       " 'validation',\n",
       " 'simply',\n",
       " 'conclusion',\n",
       " 'run',\n",
       " 'underlie',\n",
       " 'complete',\n",
       " 'addition',\n",
       " 'whether',\n",
       " 'imply',\n",
       " 'uniform',\n",
       " 'bay',\n",
       " 'interval',\n",
       " 'movement',\n",
       " 'chip',\n",
       " 'significantly',\n",
       " 'theoretical',\n",
       " 'difficult',\n",
       " 'formulation',\n",
       " 'among',\n",
       " 'code',\n",
       " 'record',\n",
       " 'artificial',\n",
       " 'refer',\n",
       " 'link',\n",
       " 'typically',\n",
       " 'delay',\n",
       " 'measurement',\n",
       " 'dimensionality',\n",
       " 'relation',\n",
       " 'reduction',\n",
       " 'place',\n",
       " 'arbitrary',\n",
       " 'pas',\n",
       " 'cause',\n",
       " 'future',\n",
       " 'sense',\n",
       " 'nature',\n",
       " 'hierarchical',\n",
       " 'guarantee',\n",
       " 'patch',\n",
       " 'extract',\n",
       " 'otherwise',\n",
       " 'international',\n",
       " 'appropriate',\n",
       " 'smaller',\n",
       " 'exponential',\n",
       " 'improvement',\n",
       " 'easily',\n",
       " 'side',\n",
       " 'derivative',\n",
       " 'relevant',\n",
       " 'robot',\n",
       " 'speed',\n",
       " 'unknown',\n",
       " 'evaluation',\n",
       " 'detect',\n",
       " 'text',\n",
       " 'family',\n",
       " 'noisy',\n",
       " 'database',\n",
       " 'embed',\n",
       " 'last',\n",
       " 'spectral',\n",
       " 'evidence',\n",
       " 'graphical',\n",
       " 'principle',\n",
       " 'robust',\n",
       " 'technical',\n",
       " 'certain',\n",
       " 'segmentation',\n",
       " 'receive',\n",
       " 'unlabeled',\n",
       " 'scene',\n",
       " 'basic',\n",
       " 'semi',\n",
       " 'return',\n",
       " 'back',\n",
       " 'uncertainty',\n",
       " 'motor',\n",
       " 'final',\n",
       " 'question',\n",
       " 'datasets',\n",
       " 'parallel',\n",
       " 'recent',\n",
       " 'cortical',\n",
       " 'effective',\n",
       " 'simulate',\n",
       " 'reason',\n",
       " 'operation',\n",
       " 'likely',\n",
       " 'shift',\n",
       " 'integrate',\n",
       " 'constrain',\n",
       " 'marginal',\n",
       " 'mix',\n",
       " 'alternative',\n",
       " 'explain',\n",
       " 'sensor',\n",
       " 'bottom',\n",
       " 'practice',\n",
       " 'track',\n",
       " 'around',\n",
       " 'mode',\n",
       " 'exactly',\n",
       " 'deviation',\n",
       " 'reach',\n",
       " 'analyze',\n",
       " 'furthermore',\n",
       " 'quadratic',\n",
       " 'operator',\n",
       " 'do',\n",
       " 'functional',\n",
       " 'message',\n",
       " 'special',\n",
       " 'understand',\n",
       " 'replace',\n",
       " 'nearest',\n",
       " 'volume',\n",
       " 'analog',\n",
       " 'subspace',\n",
       " 'color',\n",
       " 'window',\n",
       " 'inverse',\n",
       " 'polynomial',\n",
       " 'editor',\n",
       " 'stage',\n",
       " 'express',\n",
       " 'fit',\n",
       " 'classify',\n",
       " 'principal',\n",
       " 'concept',\n",
       " 'forward',\n",
       " 'necessary',\n",
       " 'count',\n",
       " 'background',\n",
       " 'feedback',\n",
       " 'symmetric',\n",
       " 'grid',\n",
       " 'dual',\n",
       " 'project',\n",
       " 'normal',\n",
       " 'stable',\n",
       " 'employ',\n",
       " 'nip',\n",
       " 'reconstruction',\n",
       " 'recurrent',\n",
       " 'self',\n",
       " 'usually',\n",
       " 'play',\n",
       " 'dependency',\n",
       " 'together',\n",
       " 'incorporate',\n",
       " 'restrict',\n",
       " 'equilibrium',\n",
       " 'plan',\n",
       " 'explore',\n",
       " 'weak',\n",
       " 'resolution',\n",
       " 'induce',\n",
       " 'desire',\n",
       " 'vertex',\n",
       " 'novel',\n",
       " 'create',\n",
       " 'diagonal',\n",
       " 'surface',\n",
       " 'inequality',\n",
       " 'repeat',\n",
       " 'infer',\n",
       " 'overlap',\n",
       " 'institute',\n",
       " 'sufficient',\n",
       " 'seem',\n",
       " 'strength',\n",
       " 'adaptation',\n",
       " 'split',\n",
       " 'recently',\n",
       " 'player',\n",
       " 'assignment',\n",
       " 'strong',\n",
       " 'miss',\n",
       " 'receptive',\n",
       " 'highly',\n",
       " 'separation',\n",
       " 'quality',\n",
       " 'extension',\n",
       " 'share',\n",
       " 'gate',\n",
       " 'digit',\n",
       " 'synapsis',\n",
       " 'variation',\n",
       " 'descent',\n",
       " 'configuration',\n",
       " 'third',\n",
       " 'cycle',\n",
       " 'avoid',\n",
       " 'divergence',\n",
       " 'remove',\n",
       " 'decomposition',\n",
       " 'intelligence',\n",
       " 'infinite',\n",
       " 'unsupervised',\n",
       " 'overall',\n",
       " 'moreover',\n",
       " 'voltage',\n",
       " 'suppose',\n",
       " 'stationary',\n",
       " 'though',\n",
       " 'clearly',\n",
       " 'recall',\n",
       " 'issue',\n",
       " 'recover',\n",
       " 'role',\n",
       " 'characteristic',\n",
       " 'approximately',\n",
       " 'learner',\n",
       " 'couple',\n",
       " 'minimization',\n",
       " 'situation',\n",
       " 'store',\n",
       " 'accurate',\n",
       " 'modify',\n",
       " 'correlate',\n",
       " 'predictive',\n",
       " 'trace',\n",
       " 'ability',\n",
       " 'actual',\n",
       " 'quite',\n",
       " 'investigate',\n",
       " 'ensemble',\n",
       " 'practical',\n",
       " 'attention',\n",
       " 'look',\n",
       " 'period',\n",
       " 'quantity',\n",
       " 'entry',\n",
       " 'short',\n",
       " 'author',\n",
       " 'biological',\n",
       " 'invariant',\n",
       " 'characterize',\n",
       " 'similarly',\n",
       " 'easy',\n",
       " 'switch',\n",
       " 'exploit',\n",
       " 'hard',\n",
       " 'near',\n",
       " 'mutual',\n",
       " 'magnitude',\n",
       " 'influence',\n",
       " 'enough',\n",
       " 'jordan',\n",
       " 'generally',\n",
       " 'pose',\n",
       " 'controller',\n",
       " 'contribution',\n",
       " 'sign',\n",
       " 'gibbs',\n",
       " 'efficiently',\n",
       " 'contour',\n",
       " 'protein',\n",
       " 'keep',\n",
       " 'tend',\n",
       " 'detector',\n",
       " 'greedy',\n",
       " 'previously',\n",
       " 'attempt',\n",
       " 'transfer',\n",
       " 'york',\n",
       " 'clear',\n",
       " 'gene',\n",
       " 'begin',\n",
       " 'ensure',\n",
       " 'http',\n",
       " 'notation',\n",
       " 'head',\n",
       " 'dependence',\n",
       " 'description',\n",
       " 'pairwise',\n",
       " 'sensory',\n",
       " 'review',\n",
       " 'identical',\n",
       " 'drive',\n",
       " 'attribute',\n",
       " 'one',\n",
       " 'whereas',\n",
       " 'carlo',\n",
       " 'monte',\n",
       " 'spectrum',\n",
       " 'indeed',\n",
       " 'typical',\n",
       " 'adapt',\n",
       " 'internal',\n",
       " 'particle',\n",
       " 'angle',\n",
       " 'velocity',\n",
       " 'almost',\n",
       " 'expansion',\n",
       " 'light',\n",
       " 'auditory',\n",
       " 'fully',\n",
       " 'letter',\n",
       " 'perceptron',\n",
       " 'heuristic',\n",
       " 'speaker',\n",
       " 'interpretation',\n",
       " 'relatively',\n",
       " 'simplify',\n",
       " 'entire',\n",
       " 'precision',\n",
       " 'specifically',\n",
       " 'collection',\n",
       " 'axis',\n",
       " 'panel',\n",
       " 'cover',\n",
       " 'faster',\n",
       " 'reflect',\n",
       " 'eigenvectors',\n",
       " 'examine',\n",
       " 'except',\n",
       " 'discriminative',\n",
       " 'engineer',\n",
       " 'technology',\n",
       " 'outperform',\n",
       " 'root',\n",
       " 'template',\n",
       " 'excitatory',\n",
       " 'grow',\n",
       " 'thank',\n",
       " 'purpose',\n",
       " 'parametric',\n",
       " 'peak',\n",
       " 'flow',\n",
       " 'come',\n",
       " 'deterministic',\n",
       " 'baseline',\n",
       " 'explicitly',\n",
       " 'partial',\n",
       " 'establish',\n",
       " 'aspect',\n",
       " 'affect',\n",
       " 'importance',\n",
       " 'arise',\n",
       " 'sequential',\n",
       " 'course',\n",
       " 'independently',\n",
       " 'whole',\n",
       " 'iterative',\n",
       " 'width',\n",
       " 'decay',\n",
       " 'rotation',\n",
       " 'sound',\n",
       " 'presence',\n",
       " 'loop',\n",
       " 'deal',\n",
       " 'logistic',\n",
       " 'exhibit',\n",
       " 'regularize',\n",
       " 'dynamical',\n",
       " 'numerical',\n",
       " 'confidence',\n",
       " 'alignment',\n",
       " 'transaction',\n",
       " 'synapse',\n",
       " 'video',\n",
       " 'depth',\n",
       " 'walk',\n",
       " 'histogram',\n",
       " 'differ',\n",
       " 'grant',\n",
       " 'five',\n",
       " 'largest',\n",
       " 'interpret',\n",
       " 'stability',\n",
       " 'onto',\n",
       " 'inhibitory',\n",
       " 'candidate',\n",
       " 'belong',\n",
       " 'list',\n",
       " 'unique',\n",
       " 'handle',\n",
       " 'trans',\n",
       " 'maintain',\n",
       " 'neighborhood',\n",
       " 'springer',\n",
       " 'stop',\n",
       " 'literature',\n",
       " 'simultaneously',\n",
       " 'solid',\n",
       " 'normalization',\n",
       " 'slightly',\n",
       " 'dirichlet',\n",
       " 'development',\n",
       " 'actually',\n",
       " 'span',\n",
       " 'greater',\n",
       " 'early',\n",
       " 'sentence',\n",
       " 'identity',\n",
       " 'locally',\n",
       " 'treat',\n",
       " 'dash',\n",
       " 'carry',\n",
       " 'classical',\n",
       " 'already',\n",
       " 'fisher',\n",
       " 'translation',\n",
       " 'display',\n",
       " 'decode',\n",
       " 'latter',\n",
       " 'differential',\n",
       " 'string',\n",
       " 'initialize',\n",
       " 'wide',\n",
       " 'linearly',\n",
       " 'svms',\n",
       " 'array',\n",
       " 'retrieval',\n",
       " 'variety',\n",
       " 'gaussians',\n",
       " 'hinton',\n",
       " 'asymptotic',\n",
       " 'child',\n",
       " 'relaxation',\n",
       " 'capacity',\n",
       " 'force',\n",
       " 'challenge',\n",
       " 'computationally',\n",
       " 'variant',\n",
       " 'character',\n",
       " 'module',\n",
       " 'correctly',\n",
       " 'uniformly',\n",
       " 'amplitude',\n",
       " 'false',\n",
       " 'others',\n",
       " 'preference',\n",
       " 'explicit',\n",
       " 'corpus',\n",
       " 'communication',\n",
       " 'neuronal',\n",
       " 'construction',\n",
       " 'fraction',\n",
       " 'open',\n",
       " 'minimal',\n",
       " 'bit',\n",
       " 'half',\n",
       " 'critical',\n",
       " 'upon',\n",
       " 'penalty',\n",
       " 'want',\n",
       " 'rely',\n",
       " 'towards',\n",
       " 'independence',\n",
       " 'sensitive',\n",
       " 'notice',\n",
       " 'parent',\n",
       " 'additive',\n",
       " 'argument',\n",
       " 'cognitive',\n",
       " 'straightforward',\n",
       " 'sparsity',\n",
       " 'adaboost',\n",
       " 'simplicity',\n",
       " 'intensity',\n",
       " 'operate',\n",
       " 'formulate',\n",
       " 'euclidean',\n",
       " 'synthetic',\n",
       " 'connectivity',\n",
       " 'divide',\n",
       " 'inner',\n",
       " 'kind',\n",
       " 'consistency',\n",
       " 'partially',\n",
       " 'manner',\n",
       " 'summarize',\n",
       " 'motivate',\n",
       " 'reasonable',\n",
       " 'prune',\n",
       " 'little',\n",
       " 'help',\n",
       " 'longer',\n",
       " 'morgan',\n",
       " 'membrane',\n",
       " 'regret',\n",
       " 'calculation',\n",
       " 'integration',\n",
       " 'white',\n",
       " 'rest',\n",
       " 'central',\n",
       " 'neuroscience',\n",
       " 'way',\n",
       " 'soft',\n",
       " 'plane',\n",
       " 'history',\n",
       " 'proportional',\n",
       " 'mathematical',\n",
       " 'black',\n",
       " 'later',\n",
       " 'enable',\n",
       " 'round',\n",
       " 'think',\n",
       " 'particularly',\n",
       " 'fail',\n",
       " 'item',\n",
       " 'laplacian',\n",
       " 'maximization',\n",
       " 'relevance',\n",
       " 'versus',\n",
       " 'balance',\n",
       " 'sufficiently',\n",
       " 'texture',\n",
       " 'vertical',\n",
       " 'difficulty',\n",
       " 'ignore',\n",
       " 'recognize',\n",
       " 'try',\n",
       " 'parse',\n",
       " 'acknowledgment',\n",
       " 'perception',\n",
       " 'body',\n",
       " 'causal',\n",
       " 'maximal',\n",
       " 'proposition',\n",
       " 'appearance',\n",
       " 'distinct',\n",
       " 'integral',\n",
       " 'discrimination',\n",
       " 'symbol',\n",
       " 'processor',\n",
       " 'regard',\n",
       " 'exploration',\n",
       " 'acoustic',\n",
       " 'dot',\n",
       " 'temperature',\n",
       " 'automatically',\n",
       " 'mass',\n",
       " 'preserve',\n",
       " 'band',\n",
       " 'hierarchy',\n",
       " 'primary',\n",
       " 'notion',\n",
       " 'organize',\n",
       " 'slow',\n",
       " 'collect',\n",
       " 'tool',\n",
       " 'row',\n",
       " 'association',\n",
       " 'cue',\n",
       " 'grammar',\n",
       " 'sum',\n",
       " 'efficiency',\n",
       " 'wavelet',\n",
       " 'definite',\n",
       " 'pick',\n",
       " 'adjust',\n",
       " 'orthogonal',\n",
       " 'essentially',\n",
       " 'prefer',\n",
       " 'especially',\n",
       " 'attractor',\n",
       " 'localization',\n",
       " 'semantic',\n",
       " 'break',\n",
       " 'competitive',\n",
       " 'foundation',\n",
       " 'completely',\n",
       " 'mention',\n",
       " 'scan',\n",
       " 'roughly',\n",
       " 'strongly',\n",
       " 'correspondence',\n",
       " 'generation',\n",
       " 'requirement',\n",
       " 'name',\n",
       " 'automatic',\n",
       " 'john',\n",
       " 'lateral',\n",
       " 'horizontal',\n",
       " 'stream',\n",
       " 'inhibition',\n",
       " 'people',\n",
       " 'naive',\n",
       " 'limitation',\n",
       " 'predictor',\n",
       " 'multivariate',\n",
       " 'circle',\n",
       " 'geometric',\n",
       " 'valid',\n",
       " 'vlsi',\n",
       " 'sort',\n",
       " 'namely',\n",
       " 'animal',\n",
       " 'fold',\n",
       " 'hyperparameters',\n",
       " 'expand',\n",
       " 'disparity',\n",
       " 'optimum',\n",
       " 'closely',\n",
       " 'suitable',\n",
       " 'impose',\n",
       " 'extraction',\n",
       " 'concern',\n",
       " 'benefit',\n",
       " 'society',\n",
       " 'reveal',\n",
       " 'option',\n",
       " 'modification',\n",
       " 'selective',\n",
       " 'experience',\n",
       " 'sensitivity',\n",
       " 'compact',\n",
       " 'phenomenon',\n",
       " 'discover',\n",
       " 'saliency',\n",
       " 'branch',\n",
       " 'unlike',\n",
       " 'setting',\n",
       " 'conclude',\n",
       " 'consequence',\n",
       " 'mark',\n",
       " 'poisson',\n",
       " 'structural',\n",
       " 'trade',\n",
       " 'batch',\n",
       " 'distinguish',\n",
       " 'currently',\n",
       " 'integer',\n",
       " 'discount',\n",
       " 'content',\n",
       " 'california',\n",
       " 'naturally',\n",
       " 'outcome',\n",
       " 'profile',\n",
       " 'highest',\n",
       " 'past',\n",
       " 'post',\n",
       " 'invariance',\n",
       " 'earlier',\n",
       " 'absolute',\n",
       " 'derivation',\n",
       " 'conventional',\n",
       " 'grind',\n",
       " 'discriminant',\n",
       " 'pool',\n",
       " 'go',\n",
       " 'feedforward',\n",
       " 'pulse',\n",
       " 'perceptual',\n",
       " 'ball',\n",
       " 'variability',\n",
       " 'effectively',\n",
       " 'priori',\n",
       " 'perturbation',\n",
       " 'success',\n",
       " 'serve',\n",
       " 'align',\n",
       " 'external',\n",
       " 'student',\n",
       " 'net',\n",
       " 'believe',\n",
       " 'traditional',\n",
       " 'nonparametric',\n",
       " 'bar',\n",
       " 'middle',\n",
       " 'kalman',\n",
       " 'successful',\n",
       " 'berkeley',\n",
       " 'beyond',\n",
       " 'identification',\n",
       " 'taylor',\n",
       " 'williams',\n",
       " 'evolution',\n",
       " 'possibly',\n",
       " 'regular',\n",
       " 'comparable',\n",
       " 'kaufmann',\n",
       " 'respond',\n",
       " 'compression',\n",
       " 'answer',\n",
       " 'vapnik',\n",
       " 'presentation',\n",
       " 'scalar',\n",
       " 'omit',\n",
       " 'residual',\n",
       " 'epoch',\n",
       " 'anneal',\n",
       " 'reconstruct',\n",
       " 'unfortunately',\n",
       " 'prototype',\n",
       " 'acknowledgement',\n",
       " 'competition',\n",
       " 'dept',\n",
       " 'ideal',\n",
       " 'benchmark',\n",
       " 'scenario',\n",
       " 'organization',\n",
       " 'successfully',\n",
       " 'formula',\n",
       " 'offer',\n",
       " 'compose',\n",
       " 'proposal',\n",
       " 'connectionist',\n",
       " 'possibility',\n",
       " 'smallest',\n",
       " 'tractable',\n",
       " 'intrinsic',\n",
       " 'plasticity',\n",
       " 'conf',\n",
       " 'hebbian',\n",
       " 'device',\n",
       " 'sutton',\n",
       " 'national',\n",
       " 'permutation',\n",
       " 'smola',\n",
       " 'major',\n",
       " 'sejnowski',\n",
       " 'digital',\n",
       " 'blind',\n",
       " 'exponentially',\n",
       " 'smoothness',\n",
       " 'feasible',\n",
       " 'consequently',\n",
       " 'away',\n",
       " 'worse',\n",
       " 'laboratory',\n",
       " 'fourier',\n",
       " 'quickly',\n",
       " 'conjugate',\n",
       " 'associative',\n",
       " 'depict',\n",
       " 'mcmc',\n",
       " 'simpler',\n",
       " 'load',\n",
       " 'postsynaptic',\n",
       " 'rise',\n",
       " 'indicator',\n",
       " 'recursive',\n",
       " 'proportion',\n",
       " 'formally',\n",
       " 'penalize',\n",
       " 'year',\n",
       " 'clique',\n",
       " 'fall',\n",
       " 'camera',\n",
       " 'observable',\n",
       " 'visible',\n",
       " 'paradigm',\n",
       " 'occurrence',\n",
       " 'eliminate',\n",
       " 'schedule',\n",
       " 'decompose',\n",
       " 'member',\n",
       " 'utility',\n",
       " 'wish',\n",
       " 'icml',\n",
       " 'wiley',\n",
       " 'physical',\n",
       " 'adopt',\n",
       " 'outlier',\n",
       " 'hyperplane',\n",
       " 'storage',\n",
       " 'widely',\n",
       " 'activate',\n",
       " 'necessarily',\n",
       " 'physic',\n",
       " 'pathway',\n",
       " 'worst',\n",
       " 'utilize',\n",
       " 'factorization',\n",
       " 'diagram',\n",
       " 'moment',\n",
       " 'david',\n",
       " 'marginals',\n",
       " 'read',\n",
       " 'topology',\n",
       " 'gray',\n",
       " 'expensive',\n",
       " 'trivial',\n",
       " 'multinomial',\n",
       " 'neurosci',\n",
       " 'popular',\n",
       " 'regime',\n",
       " 'seek',\n",
       " 'stag',\n",
       " 'never',\n",
       " 'despite',\n",
       " 'diffusion',\n",
       " 'summary',\n",
       " 'stanford',\n",
       " 'lie',\n",
       " 'fundamental',\n",
       " 'realistic',\n",
       " 'teacher',\n",
       " 'outline',\n",
       " 'outside',\n",
       " 'mistake',\n",
       " 'lasso',\n",
       " 'interpolation',\n",
       " 'hmms',\n",
       " 'workshop',\n",
       " 'accurately',\n",
       " 'corollary',\n",
       " 'modulation',\n",
       " 'observer',\n",
       " 'perspective',\n",
       " 'usual',\n",
       " 'empirically',\n",
       " 'duration',\n",
       " 'applicable',\n",
       " 'hybrid',\n",
       " 'equally',\n",
       " 'distortion',\n",
       " 'poor',\n",
       " 'enforce',\n",
       " 'extra',\n",
       " 'theoretic',\n",
       " 'lack',\n",
       " 'precisely',\n",
       " 'alone',\n",
       " 'multiply',\n",
       " 'retina',\n",
       " 'geometry',\n",
       " 'pseudo',\n",
       " 'perfect',\n",
       " 'check',\n",
       " 'audio',\n",
       " 'equivalence',\n",
       " 'ghahramani',\n",
       " 'incremental',\n",
       " 'winner',\n",
       " 'subsequent',\n",
       " 'contribute',\n",
       " 'reproduce',\n",
       " 'drop',\n",
       " 'thesis',\n",
       " 'radius',\n",
       " 'dominate',\n",
       " 'separable',\n",
       " 'throughout',\n",
       " 'strictly',\n",
       " 'initially',\n",
       " 'verify',\n",
       " 'access',\n",
       " 'transistor',\n",
       " 'tangent',\n",
       " 'verlag',\n",
       " 'merge',\n",
       " 'potentially',\n",
       " 'diag',\n",
       " 'insight',\n",
       " 'preliminary',\n",
       " 'extremely',\n",
       " 'mask',\n",
       " 'intractable',\n",
       " 'terminal',\n",
       " 'accept',\n",
       " 'intermediate',\n",
       " 'decide',\n",
       " 'iterate',\n",
       " 'radial',\n",
       " 'continue',\n",
       " 'percentage',\n",
       " 'initialization',\n",
       " 'vote',\n",
       " 'bandwidth',\n",
       " 'hardware',\n",
       " 'categorization',\n",
       " 'boltzmann',\n",
       " 'michael',\n",
       " 'ass',\n",
       " 'whenever',\n",
       " 'claim',\n",
       " 'shall',\n",
       " 'concentration',\n",
       " 'happen',\n",
       " 'double',\n",
       " 'backward',\n",
       " 'plus',\n",
       " 'school',\n",
       " 'correction',\n",
       " 'execute',\n",
       " 'commonly',\n",
       " 'generic',\n",
       " 'origin',\n",
       " 'powerful',\n",
       " 'gamma',\n",
       " 'eigenvector',\n",
       " 'resource',\n",
       " 'sometimes',\n",
       " 'inside',\n",
       " 'overfitting',\n",
       " 'parameterized',\n",
       " 'localize',\n",
       " 'precise',\n",
       " 'optimality',\n",
       " 'lattice',\n",
       " 'nearly',\n",
       " 'surround',\n",
       " 'arrive',\n",
       " 'wise',\n",
       " 'sigmoid',\n",
       " 'prevent',\n",
       " 'analogous',\n",
       " 'superior',\n",
       " 'analytically',\n",
       " 'absence',\n",
       " 'hopfield',\n",
       " 'relax',\n",
       " 'robustness',\n",
       " 'complicate',\n",
       " 'price',\n",
       " 'explanation',\n",
       " 'london',\n",
       " 'rewrite',\n",
       " 'conductance',\n",
       " 'style',\n",
       " 'offset',\n",
       " 'asymptotically',\n",
       " 'fewer',\n",
       " 'obvious',\n",
       " 'guide',\n",
       " 'essential',\n",
       " 'existence',\n",
       " 'software',\n",
       " 'statistically',\n",
       " 'singular',\n",
       " 'zhang',\n",
       " 'somewhat',\n",
       " 'quantify',\n",
       " 'intuitively',\n",
       " 'symmetry',\n",
       " 'propagate',\n",
       " 'phrase',\n",
       " 'dictionary',\n",
       " 'behavioral',\n",
       " 'harmonic',\n",
       " 'separately',\n",
       " 'leaf',\n",
       " 'backpropagation',\n",
       " 'surprise',\n",
       " 'person',\n",
       " 'relational',\n",
       " 'static',\n",
       " ...]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmodel.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -175628075.89487827\n",
      "The upper bound on perplexity: 83.43404272359969\n"
     ]
    }
   ],
   "source": [
    "ll = model.logLikelihood(sparsevector)\n",
    "lp = model.logPerplexity(sparsevector)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[20, 83, 175, 165...|[0.00918584223962...|\n",
      "|    1|[95, 125, 33, 2, ...|[0.00938510614558...|\n",
      "|    2|[9, 172, 10, 186,...|[0.01147312123454...|\n",
      "|    3|[24, 41, 23, 232,...|[0.00992664812854...|\n",
      "|    4|[0, 81, 140, 134,...|[0.00765284871033...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "\n",
    "# Number of terms in topics\n",
    "numTerms = 8\n",
    "\n",
    "topics = model.describeTopics(numTerms)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------+\n",
      "|topics_words                                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "|[manifold, dimensionality, subspace, operator, embed, principal, coordinate, reduction]|\n",
      "|[patch, segmentation, generative, vision, frame, scene, contour, pose]                 |\n",
      "|[category, nearest, query, concept, split, database, retrieval, code]                  |\n",
      "|[boost, user, online, player, learner, weak, equilibrium, play]                        |\n",
      "|[cortex, delay, cortical, motor, synapsis, record, auditory, excitatory]               |\n",
      "|[chip, receptive, attention, analog, head, adaptation, voltage, velocity]              |\n",
      "|[reinforcement, trajectory, robot, plan, environment, controller, world, future]       |\n",
      "|[gibbs, chain, carlo, monte, particle, variational, message, processor]                |\n",
      "|[semi, spectral, unlabeled, formulation, vertex, speaker, dual, marginal]              |\n",
      "|[language, gene, hierarchical, link, sentence, corpus, parse, grammar]                 |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY THE TOPIC DISTRIBUTION\n",
    "\n",
    "def indices_to_terms(vocabulary):\n",
    "    def indices_to_terms(xs):\n",
    "        return [vocabulary[int(x)] for x in xs]\n",
    "    return udf(indices_to_terms, ArrayType(StringType()))\n",
    "\n",
    "topics_with_terms = topics.withColumn(\n",
    "    \"topics_words\", indices_to_terms(cvmodel.vocabulary)(\"termIndices\"))\n",
    "\n",
    "#topics_with_terms.select(['topic','topics_words']).show(20,False)\n",
    "topics_with_terms.select(['topics_words']).show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: vector (nullable = true)\n",
      " |-- topicDistribution: vector (nullable = true)\n",
      "\n",
      "+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|_1  |topicDistribution                                                                                                                                                                                            |\n",
      "+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1   |[0.061481134491564816,0.09124081090577164,0.164676129777718,0.02353193674583338,0.032919301265873085,0.13291080481908854,0.3639027018535085,0.047934166590357666,0.02497048465622115,0.05643252889406327]    |\n",
      "|10  |[0.025387459919016874,0.01949383681986061,0.02565124844889841,0.02343866316962993,0.7590168159804711,0.03575270789085832,0.026115014939695654,0.04130350742495086,0.023877409479480513,0.019963335927137563] |\n",
      "|100 |[0.007836027741138054,0.007347197067312454,0.013030503086356723,0.01338803923271972,0.9144718493944135,0.01053870101597964,0.008600960251059695,0.008944306625465432,0.0075839047848158,0.008258510800738871]|\n",
      "|1000|[0.1344048580483015,0.03215906923889685,0.0759559978505522,0.32888239248244927,0.02543895049375816,0.027011800964247726,0.07106641374728784,0.259977838731702,0.02323767941232421,0.021864999030480257]      |\n",
      "|1001|[0.10161751748453825,0.04140820140529277,0.03429797514861483,0.6288324866382252,0.03784383279170714,0.028748103992854553,0.025205052257128848,0.04039634019610165,0.02727524915317768,0.03437524093235901]   |\n",
      "|1002|[0.07697055343890737,0.3637256482242009,0.029976391832328354,0.025268060012122794,0.013658789413070799,0.09527542825609697,0.020996108957079603,0.3212279964788442,0.023999245365233617,0.028901778022115517]|\n",
      "|1003|[0.054683572246420634,0.06362906979833453,0.048356584363241466,0.0777775340557563,0.3272964483304549,0.22400197471934205,0.03495359094587257,0.05280219680344366,0.08586504812904579,0.030633980608088102]   |\n",
      "|1004|[0.01479726055955422,0.01331288824108569,0.021421475050215962,0.024849073147855824,0.09832468534459833,0.27739554447394815,0.029877474283484588,0.3548825754065003,0.015718030675689516,0.1494209928170673]  |\n",
      "|1005|[0.03425092590327865,0.028017420771520862,0.4192749326664552,0.02804163896612293,0.04503043629421786,0.21313704633866962,0.01741205672893668,0.18155207665440676,0.01895840727974844,0.014325058396642993]   |\n",
      "|1006|[0.012568523988974602,0.01018549424652349,0.24553137276315173,0.009696303093149393,0.0824441228857137,0.3208092249707865,0.008766435548225319,0.2941935287272471,0.008731386940468811,0.007073606835759341]  |\n",
      "+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shows the result\n",
    "docTopic = model.transform(sparsevector)\n",
    "docTopic.printSchema()\n",
    "docTopic.select(['_1','topicDistribution']).show(10,truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
